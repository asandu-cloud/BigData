{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a1a9ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bd3fa3a",
   "metadata": {},
   "source": [
    "## Importing all dependencies for the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe686ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import findspark\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp, to_date, year, month\n",
    "import time \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version   :\", sys.version)\n",
    "print(\"JAVA_HOME before :\", os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "JAVA_HOME = \"/opt/homebrew/Cellar/openjdk@11/11.0.29/libexec/openjdk.jdk/Contents/Home\"\n",
    "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "os.environ[\"PATH\"] = os.path.join(JAVA_HOME, \"bin\") + \":\" + os.environ[\"PATH\"]\n",
    "\n",
    "print(\"JAVA_HOME after  :\", os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "import subprocess\n",
    "print(\"\\njava -version from this kernel:\")\n",
    "print(subprocess.check_output([\"java\", \"-version\"], stderr=subprocess.STDOUT).decode())\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"test_jvm\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"\\nSpark version:\", spark.version)\n",
    "\n",
    "# Tiny test job\n",
    "spark.range(5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7860e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_root = Path(\n",
    "        subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"])\n",
    "        .decode()\n",
    "        .strip()\n",
    "    )\n",
    "except Exception:\n",
    "    project_root = Path.cwd().parent\n",
    "\n",
    "print(\"PROJECT ROOT:\", project_root)\n",
    "\n",
    "raw_dir = project_root / \"data\" / \"raw\"\n",
    "print(\"RAW DATA DIR:\", raw_dir)\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"IRA_Tweets_Task1\")\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"6g\")      # adjust down/up depending on your RAM\n",
    "        .config(\"spark.executor.memory\", \"6g\")    # local = same as driver\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"multiLine\", \"true\")\n",
    "        .option(\"escape\", \"\\\"\")\n",
    "        .csv(str(raw_dir))\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "print(\"Total rows:\", df.count())\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8862b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"following\", \"followers\", \"updates\", \"retweet\", \"new_june_2018\"]\n",
    "\n",
    "for c in numeric_cols:\n",
    "    df = df.withColumn(c, col(c).cast(\"int\"))\n",
    "\n",
    "df.select(numeric_cols).summary(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\") \\\n",
    "  .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b28dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tweets = df.count()\n",
    "n_authors = df.select(countDistinct(\"author\").alias(\"n_authors\")).first()[\"n_authors\"]\n",
    "n_ext_authors = df.select(countDistinct(\"external_author_id\").alias(\"n_ext_authors\")).first()[\"n_ext_authors\"]\n",
    "avg_tweets_per_author = total_tweets / n_authors\n",
    "\n",
    "summary_df = spark.createDataFrame(\n",
    "    [(total_tweets, n_authors, n_ext_authors, avg_tweets_per_author)],\n",
    "    [\"total_tweets\", \"n_authors\", \"n_external_authors\", \"avg_tweets_per_author\"]\n",
    ")\n",
    "\n",
    "summary_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Languages\n",
    "lang_dist = (\n",
    "    df.groupBy(\"language\")\n",
    "      .count()\n",
    "      .withColumn(\"pct\", col(\"count\") / total_tweets)\n",
    "      .orderBy(desc(\"count\"))\n",
    ")\n",
    "lang_dist.show(20, truncate=False)\n",
    "\n",
    "# Regions\n",
    "region_dist = (\n",
    "    df.groupBy(\"region\")\n",
    "      .count()\n",
    "      .withColumn(\"pct\", col(\"count\") / total_tweets)\n",
    "      .orderBy(desc(\"count\"))\n",
    ")\n",
    "region_dist.show(20, truncate=False)\n",
    "\n",
    "# Account type / category / post type\n",
    "df.groupBy(\"account_type\").count().orderBy(desc(\"count\")).show(20, truncate=False)\n",
    "df.groupBy(\"account_category\").count().orderBy(desc(\"count\")).show(20, truncate=False)\n",
    "df.groupBy(\"post_type\").count().orderBy(desc(\"count\")).show(20, truncate=False)\n",
    "\n",
    "# Retweet vs original\n",
    "retweet_dist = (\n",
    "    df.groupBy(\"retweet\")\n",
    "      .count()\n",
    "      .withColumn(\"pct\", col(\"count\") / total_tweets)\n",
    "      .orderBy(desc(\"count\"))\n",
    ")\n",
    "retweet_dist.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfe4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df.withColumn(\n",
    "    \"publish_ts\",\n",
    "    to_timestamp(\"publish_date\", \"M/d/yyyy H:mm\")   # flexible 1 or 2 digits\n",
    ")\n",
    "\n",
    "df_time.select(\n",
    "    min(\"publish_ts\").alias(\"min_ts\"),\n",
    "    max(\"publish_ts\").alias(\"max_ts\")\n",
    ").show(truncate=False)\n",
    "\n",
    "df_daily = (\n",
    "    df_time\n",
    "        .withColumn(\"date\", to_date(\"publish_ts\"))\n",
    "        .groupBy(\"date\")\n",
    "        .count()\n",
    "        .orderBy(\"date\")\n",
    ")\n",
    "\n",
    "df_daily.show(5)\n",
    "\n",
    "daily_pd = df_daily.toPandas()\n",
    "daily_pd[\"date\"] = pd.to_datetime(daily_pd[\"date\"])\n",
    "daily_pd = daily_pd.sort_values(\"date\")\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(daily_pd[\"date\"], daily_pd[\"count\"], linewidth=1)\n",
    "plt.title(\"Daily Tweet Volume\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Tweets per Day\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
